cls_token torch.Size([1, 1, 768])
reg_token torch.Size([1, 4, 768])
reg_token torch.Size([1, 4, 768])
HAS_REGISTERS=True
NUMBER_OF_REGISTERS=4
Classification head for vit_base_patch14_reg4_dinov2.lvd142m loaded successfully
block_0
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_1
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_2
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_3
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_4
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_5
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_6
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_7
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_8
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_9
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_10
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
block_11
	q shape torch.Size([1, 12, 1374, 64])
	k shape torch.Size([1, 12, 1374, 64])
	Attention Map shape before softmax torch.Size([1, 12, 1374, 1374])
	Attention Map shape after softmax torch.Size([1, 12, 1374, 1374])
Top 5 classes:
	243 : bull mastiff   		value = 6.962	 prob = 41.7%
	242 : boxer          		value = 5.190	 prob = 7.1%
	254 : pug, pug-dog   		value = 3.868	 prob = 1.9%
	245 : French bulldog 		value = 3.265	 prob = 1.0%
	260 : chow, chow chow		value = 3.250	 prob = 1.0%
=== INPUT CHECK ===
shape: torch.Size([1, 3, 518, 518])
dtype: torch.float32
min / max / mean: -2.1179039478302 2.640000104904175 0.010741129517555237
contains NaNs: False

=== MODEL PREDICTIONS CHECK ===
predictions shape: torch.Size([1, 1000])
predictions contains NaNs: False
softmax sum: 1.0000005960464478

=== TOP-5 PREDICTIONS ===
Top 5 classes:
Top 5 classes:
243 : bull mastiff   		value = 6.962	 prob = 41.7%
242 : boxer          		value = 5.190	 prob = 7.1%
254 : pug, pug-dog   		value = 3.868	 prob = 1.9%
245 : French bulldog 		value = 3.265	 prob = 1.0%
260 : chow, chow chow		value = 3.250	 prob = 1.0%

=== VISUALIZATION ===
Input shape: torch.Size([1, 3, 518, 518])

block_0:
  Mean: -0.0005
  Std:  0.0076
  Min:  -0.0380
  Max:  0.0487
  Range: 0.0867

block_1:
  Mean: -0.0004
  Std:  0.0077
  Min:  -0.0386
  Max:  0.0487
  Range: 0.0873

block_2:
  Mean: -0.0004
  Std:  0.0077
  Min:  -0.0391
  Max:  0.0484
  Range: 0.0875

block_3:
  Mean: 0.0011
  Std:  0.0079
  Min:  -0.0378
  Max:  0.0513
  Range: 0.0891

block_4:
  Mean: -0.0005
  Std:  0.0085
  Min:  -0.0384
  Max:  0.0477
  Range: 0.0861

block_5:
  Mean: -0.0066
  Std:  0.0087
  Min:  -0.0427
  Max:  0.0358
  Range: 0.0786

block_6:
  Mean: -0.0094
  Std:  0.0106
  Min:  -0.0468
  Max:  0.0361
  Range: 0.0829

block_7:
  Mean: -0.0207
  Std:  0.0133
  Min:  -0.0666
  Max:  0.0246
  Range: 0.0913

block_8:
  Mean: -0.0354
  Std:  0.0217
  Min:  -0.0994
  Max:  0.0367
  Range: 0.1361

block_9:
  Mean: -0.0455
  Std:  0.0489
  Min:  -0.1877
  Max:  0.1138
  Range: 0.3015

block_10:
  Mean: -0.1238
  Std:  0.0734
  Min:  -0.3321
  Max:  0.1262
  Range: 0.4583

block_11:
  Mean: -0.2851
  Std:  0.1105
  Min:  -0.5476
  Max:  0.0208
  Range: 0.5684
block_0 torch.Size([1, 12, 1374, 1374])
block_1 torch.Size([1, 12, 1374, 1374])
block_2 torch.Size([1, 12, 1374, 1374])
block_3 torch.Size([1, 12, 1374, 1374])
block_4 torch.Size([1, 12, 1374, 1374])
block_5 torch.Size([1, 12, 1374, 1374])
block_6 torch.Size([1, 12, 1374, 1374])
block_7 torch.Size([1, 12, 1374, 1374])
block_8 torch.Size([1, 12, 1374, 1374])
block_9 torch.Size([1, 12, 1374, 1374])
block_10 torch.Size([1, 12, 1374, 1374])
block_11 torch.Size([1, 12, 1374, 1374])
Attention shape: torch.Size([37, 37])
Min: 0.0007
Max: 0.0007
Mean: 0.0007
Sum: 1.0000
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
torch.Size([1, 1, 37, 37])
Initializing LRP model...
Transferring weights...
lrp pos_embed shape: torch.Size([1, 1374, 768])
Handling pos_embed mismatch: torch.Size([1, 1374, 768]) vs torch.Size([1, 1369, 768])
Weight transfer result: <All keys matched successfully>
Running CheferCAM...
Prediction: bull mastiff
CheferCAM visualization saved.
